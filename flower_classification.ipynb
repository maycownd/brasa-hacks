{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flower_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_wX33Ve6iSB"
      },
      "source": [
        "# Image Classification Using Machine Learning\n",
        "\n",
        "Guilherme Franzé\n",
        "\n",
        "Maycown Miranda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSPwgGD-6wE8"
      },
      "source": [
        "## Importing all necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roNRtiToAqDJ"
      },
      "source": [
        "# bibliotecas de modelos de machine learning\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# bibliotecas de preparação de dados\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# biblioteca de visualização\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# biblioteca de processamento de imagens\n",
        "from tensorflow.keras import datasets, utils\n",
        "from PIL import Image\n",
        "# bibliotecas utilitárias\n",
        "import pathlib\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI-MWxSot_MG"
      },
      "source": [
        "# 1. Business Understanding\n",
        "\n",
        "### `- What is the problem we want to solve?`\n",
        "  - Flower.co spends more than 10 hours per day classifying images from flowers manually in order to catalog them in their website. Since the classification is manual, approximatelly 40% of the tags that are displayed in the marketplace are wrong.\n",
        "\n",
        "### `- Why is it important to solve the problem?`\n",
        "  - 50% of the revenue comes from the digital marketplace.\n",
        "\n",
        "### `- What are the expected results?`\n",
        "  - Increase the number of correct tags displayed in the marketplace\n",
        "\n",
        "### `- What is the success criteria?`\n",
        "  - At least 70% of the images correctly classied.\n",
        "\n",
        "### `- What are the expected delivery?`\n",
        "  - Machine learning binary classification model to classify images automatically\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 2. Data Understanding\n",
        "\n",
        "### - Getting all the images for the exercise \n",
        "\n",
        "Directory structure:\n",
        "- flowers\n",
        "  - flower_photos\n",
        "    - daisy\n",
        "    - dandelion\n",
        "    - roses\n",
        "    - sunflowers\n",
        "    - tulips\n",
        "    - LICENSE.txt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fmSn6CpKj1s"
      },
      "source": [
        "# Parsing the dataset URL\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "# Getting the necessary files\n",
        "data_dir = utils.get_file(\n",
        "    origin=dataset_url, \n",
        "    fname='/content/flower_photos.tgz',\n",
        "    cache_dir='/content/flowers', \n",
        "    cache_subdir='/content/flowers',\n",
        "    extract=True\n",
        "    )\n",
        "# Parsing the directory tree to a variable\n",
        "data_dir = pathlib.Path('/content/flowers/flower_photos')\n",
        "data_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYYA50BH7yym"
      },
      "source": [
        "### - Exploring the image shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkP6obBMLQ6i"
      },
      "source": [
        "# Getting all the sunflower images to a list variable\n",
        "sunflowers = list(data_dir.glob('sunflowers/*'))\n",
        "print(len(sunflowers))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ornc-f4dxCnp"
      },
      "source": [
        "# Displaying top 5 sunflower images path\n",
        "sunflowers[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BvfyFKzxekl"
      },
      "source": [
        "def load_image(infilename: str) -> np.array:\n",
        "    \"\"\"\n",
        "    Loads the image located at `infilename`  address and transforms it into a \n",
        "    `np.array` following the RGB color space pattern. The output is a 3 \n",
        "    dimensions vector [m, n, 3].\n",
        "    \"\"\"\n",
        "    img = Image.open(infilename)\n",
        "    img.load()\n",
        "    data = np.asarray( img, dtype=\"int32\" )\n",
        "    return data\n",
        "\n",
        "# Checking the shape of one image\n",
        "image_tmp = load_image(sunflowers[3])\n",
        "# The 'shape' attribute returns the height, width and channel \n",
        "# dimensions, respectivelly\n",
        "print(f'Image shape: {image_tmp.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgQsrllm_ekc"
      },
      "source": [
        "# Displaying the image\n",
        "fig,ax = plt.subplots(1,1,figsize=(7,7))\n",
        "ax.imshow(image_tmp)\n",
        "ax.set_xlabel('width, [px]')\n",
        "ax.set_ylabel('height, [px]')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYIBqG4hyMkJ"
      },
      "source": [
        "# Now we got to check if all the images have the same size\n",
        "# In order to do so, let's create a numpy array with all the shapes stored\n",
        "imgs_shapes = []\n",
        "for img_path in sunflowers:\n",
        "  # Reading the image\n",
        "  img = load_image(img_path)\n",
        "  # Storing the shape\n",
        "  imgs_shapes.append(np.array(img.shape))\n",
        "# Converting the list to a numpy array\n",
        "imgs_shapes = np.array(imgs_shapes)\n",
        "# Printing the shapes\n",
        "print(imgs_shapes.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_OWkYgQzQDJ"
      },
      "source": [
        "# Displaying three histograms. The first corresponds to heights,\n",
        "# the second corresponds to widths \n",
        "# and the latter corresponds to channels\n",
        "fig,ax = plt.subplots(1,3,figsize=(14,3))\n",
        "\n",
        "ax[0].hist(imgs_shapes[:,0],color='w',ec='k',label='heights')\n",
        "ax[1].hist(imgs_shapes[:,1],color='y',ec='k',label='widhts')\n",
        "ax[2].hist(imgs_shapes[:,2],color='g',ec='k',label='channels')\n",
        "# Applying legends\n",
        "ax[0].legend()\n",
        "ax[1].legend()\n",
        "ax[2].legend()\n",
        "# Applying ylabel\n",
        "ax[0].set_ylabel('Frequency')\n",
        "# Getting a tight layout\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDh9zOnKMo6h"
      },
      "source": [
        "We conclude the images have unequal sizes. Therefore, for the data preparation, we have to develop a function to normalize the image's size for each flower category.\n",
        "\n",
        "### - Normalizing images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RrS_yJ3zQIz"
      },
      "source": [
        "def normalize_size(\n",
        "    img : np.array,\n",
        "    img_path : str,\n",
        "    size : tuple = (200,200)\n",
        "    ) -> None:\n",
        "    \"\"\"Function to normalize the image size.\"\"\"\n",
        "    try:\n",
        "      # Convert from array to Image PIL object\n",
        "      img_pil = Image.fromarray(img.astype(np.uint8))\n",
        "      # Generate the thumbnail\n",
        "      img_pil = img_pil.resize(size)\n",
        "      # Saving the image\n",
        "      img_pil.save(img_path, \"JPEG\")\n",
        "    except IOError:\n",
        "        print(f\"Cannot create thumbnail for '{img_path}'\")\n",
        "\n",
        "# Running the function for each image\n",
        "for img_path in sunflowers:\n",
        "  # Reading the image\n",
        "  img = load_image(img_path)\n",
        "  # Reshaping the image\n",
        "  normalize_size(img,img_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ8nQh4Mg7Jv"
      },
      "source": [
        "# Checking the shape of one image\n",
        "image_tmp = load_image(sunflowers[3])\n",
        "# The 'shape' attribute returns the height, width and channel \n",
        "# dimensions, respectivelly\n",
        "print(f'Image shape: {image_tmp.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yVi7APVg7Yr"
      },
      "source": [
        "# Displaying the image\n",
        "fig,ax = plt.subplots(1,1,figsize=(7,7))\n",
        "ax.imshow(image_tmp)\n",
        "ax.set_xlabel('width, [px]')\n",
        "ax.set_ylabel('height, [px]')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuHpWAvR2AQt"
      },
      "source": [
        "### - Exploring the image distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Erhr-SL74zNG"
      },
      "source": [
        "# Getting all the sunflower images to a list variable\n",
        "sunflowers = list(data_dir.glob('sunflowers/*'))\n",
        "print(len(sunflowers))\n",
        "\n",
        "# Loading some image again\n",
        "sunflower_tmp = load_image(sunflowers[3])\n",
        "# The 'shape' attribute returns the height, width and channel \n",
        "# dimensions, respectivelly\n",
        "print(f'Image shape: {sunflower_tmp.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vObEXUl4bhX"
      },
      "source": [
        "# Displaying three color space pixel histograms. The first corresponds to red,\n",
        "# the second corresponds to green and the latter corresponds to blue channels\n",
        "fig,ax = plt.subplots(1,1,figsize=(13,5))\n",
        "\n",
        "ax.hist(sunflower_tmp[:,:,0].flatten(),color='r',alpha=0.4,ec='k',label='red')\n",
        "ax.hist(sunflower_tmp[:,:,1].flatten(),color='g',alpha=0.4,ec='k',label='green')\n",
        "ax.hist(sunflower_tmp[:,:,2].flatten(),color='b',alpha=0.6,ec='k',label='blue')\n",
        "# Applying legends\n",
        "ax.legend()\n",
        "# Applying ylabel\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_xlabel('Pixel color distribution')\n",
        "# Getting a tight layout\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEV-LGgi4bm5"
      },
      "source": [
        "# Getting all the sunflower images to a list variable\n",
        "roses = list(data_dir.glob('roses/*'))\n",
        "print(len(roses))\n",
        "\n",
        "# Loading some image again\n",
        "rose_tmp = load_image(roses[30])\n",
        "# The 'shape' attribute returns the height, width and channel \n",
        "# dimensions, respectivelly\n",
        "print(f'Image shape: {rose_tmp.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzyrkAmm57q9"
      },
      "source": [
        "# Displaying three color space pixel histograms. The first corresponds to red,\n",
        "# the second corresponds to green and the latter corresponds to blue channels\n",
        "fig,ax = plt.subplots(1,1,figsize=(13,5))\n",
        "\n",
        "ax.hist(rose_tmp[:,:,0].flatten(),color='r',alpha=0.4,ec='k',label='red')\n",
        "ax.hist(rose_tmp[:,:,1].flatten(),color='g',alpha=0.4,ec='k',label='green')\n",
        "ax.hist(rose_tmp[:,:,2].flatten(),color='b',alpha=0.6,ec='k',label='blue')\n",
        "# Applying legends\n",
        "ax.legend()\n",
        "# Applying ylabel\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_xlabel('Pixel color distribution')\n",
        "# Getting a tight layout\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvTPk4TI6e0-"
      },
      "source": [
        "It looks like the red is more intense in the pictures containing roses. Therefore, we should investigate if this behavior is present throught all the roses dataset.\n",
        "\n",
        "### - Exploring statistical metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8bLwFHC570h"
      },
      "source": [
        "# Let's create a numpy array with the median values for each \n",
        "# pixel intensity distribution within the RGB color space\n",
        "roses_mean = []\n",
        "for img_path in roses:\n",
        "  # Reading the image\n",
        "  img = load_image(img_path)\n",
        "  # Storing the median\n",
        "  roses_mean.append([np.median(img[:,:,0]),\n",
        "                     np.median(img[:,:,1]),\n",
        "                     np.median(img[:,:,2]),\n",
        "                     ])\n",
        "# Converting the list to a numpy array\n",
        "roses_mean = np.array(roses_mean)\n",
        "# Printing the shapes\n",
        "print(roses_mean.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_3UTr2a61zL"
      },
      "source": [
        "# Now, we do the same with the sunflowers\n",
        "sunflowers_mean = []\n",
        "for img_path in sunflowers:\n",
        "  # Reading the image\n",
        "  img = load_image(img_path)\n",
        "  # Storing the median\n",
        "  sunflowers_mean.append([np.mean(img[:,:,0]),\n",
        "                          np.mean(img[:,:,1]),\n",
        "                          np.mean(img[:,:,2]),\n",
        "                          ])\n",
        "# Converting the list to a numpy array\n",
        "sunflowers_mean = np.array(sunflowers_mean)\n",
        "# Printing the shapes\n",
        "print(sunflowers_mean.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQXWk8lS615W"
      },
      "source": [
        "# Let's visualize the results\n",
        "fig,ax = plt.subplots(2,1,figsize=(13,7),sharex=True,sharey=True)\n",
        "\n",
        "ax[0].hist(roses_mean[:,0].flatten(),bins=np.arange(0,256,10),color='r',alpha=0.4,ec='k',label='red')\n",
        "ax[0].hist(roses_mean[:,1].flatten(),bins=np.arange(0,256,10),color='g',alpha=0.4,ec='k',label='green')\n",
        "ax[0].hist(roses_mean[:,2].flatten(),bins=np.arange(0,256,10),color='b',alpha=0.6,ec='k',label='blue')\n",
        "ax[1].hist(sunflowers_mean[:,0].flatten(),bins=np.arange(0,256,10),color='r',alpha=0.4,ec='k',label='red')\n",
        "ax[1].hist(sunflowers_mean[:,1].flatten(),bins=np.arange(0,256,10),color='g',alpha=0.4,ec='k',label='green')\n",
        "ax[1].hist(sunflowers_mean[:,2].flatten(),bins=np.arange(0,256,10),color='b',alpha=0.6,ec='k',label='blue')\n",
        "# Applying legends\n",
        "ax[0].legend()\n",
        "# Applying ylabel\n",
        "ax[0].set_ylabel('Frequency')\n",
        "ax[1].set_ylabel('Frequency')\n",
        "ax[1].set_xlabel('Pixel color distribution')\n",
        "# Applying titles\n",
        "ax[0].set_title('Roses')\n",
        "ax[1].set_title('Sunflowers')\n",
        "fig.suptitle('Mean Pixel Distribution for each channel within the RGB Color Space')\n",
        "# Getting a tight layout\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(top=0.9)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EHD8WaVNaz2"
      },
      "source": [
        "One can depict from the figure above that sunflowers have less overlap between blue, green and red channels for pixel intensity values bellow 75. Therefore, the median of the pixel intensity is a great feature candidate to compose the modeling dataset. \n",
        "\n",
        "Another conclusion that one can make is regarding the greater red intensity present on roses when compared to sunflowers.\n",
        "\n",
        "Now, we have to check some other statistics in order to evaluate possible features to compose our modeling dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHLHzUeG62AC"
      },
      "source": [
        "# Let's create a numpy array with the standard deviation values for each \n",
        "# pixel intensity distribution within the RGB color space\n",
        "roses_std = []\n",
        "for img_path in roses:\n",
        "  # Reading the image\n",
        "  img = load_image(img_path)\n",
        "  # Storing the std\n",
        "  roses_std.append([np.std(img[:,:,0]),\n",
        "                    np.std(img[:,:,1]),\n",
        "                    np.std(img[:,:,2]),\n",
        "                    ])\n",
        "# Converting the list to a numpy array\n",
        "roses_std = np.array(roses_std)\n",
        "# Printing the shapes\n",
        "print(roses_std.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLJ6fnBe97PK"
      },
      "source": [
        "# Now, we do the same with the sunflowers\n",
        "sunflowers_std = []\n",
        "for img_path in sunflowers:\n",
        "  # Reading the image\n",
        "  img = load_image(img_path)\n",
        "  # Storing the median\n",
        "  sunflowers_std.append([np.std(img[:,:,0]),\n",
        "                         np.std(img[:,:,1]),\n",
        "                         np.std(img[:,:,2]),\n",
        "                         ])\n",
        "# Converting the list to a numpy array\n",
        "sunflowers_std = np.array(sunflowers_std)\n",
        "# Printing the shapes\n",
        "print(sunflowers_std.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhkrYKr997WI"
      },
      "source": [
        "# Let's visualize the results\n",
        "fig,ax = plt.subplots(2,1,figsize=(13,7),sharex=True,sharey=True)\n",
        "\n",
        "ax[0].hist(roses_std[:,0].flatten(),bins=np.arange(0,125,5),color='r',alpha=0.4,ec='k',label='red')\n",
        "ax[0].hist(roses_std[:,1].flatten(),bins=np.arange(0,125,5),color='g',alpha=0.4,ec='k',label='green')\n",
        "ax[0].hist(roses_std[:,2].flatten(),bins=np.arange(0,125,5),color='b',alpha=0.6,ec='k',label='blue')\n",
        "ax[1].hist(sunflowers_std[:,0].flatten(),bins=np.arange(0,125,5),color='r',alpha=0.4,ec='k',label='red')\n",
        "ax[1].hist(sunflowers_std[:,1].flatten(),bins=np.arange(0,125,5),color='g',alpha=0.4,ec='k',label='green')\n",
        "ax[1].hist(sunflowers_std[:,2].flatten(),bins=np.arange(0,125,5),color='b',alpha=0.6,ec='k',label='blue')\n",
        "# Applying legends\n",
        "ax[0].legend()\n",
        "# Applying ylabel\n",
        "ax[0].set_ylabel('Frequency')\n",
        "ax[1].set_ylabel('Frequency')\n",
        "ax[1].set_xlabel('Pixel color distribution')\n",
        "# Applying titles\n",
        "ax[0].set_title('Roses')\n",
        "ax[1].set_title('Sunflowers')\n",
        "fig.suptitle('Standard Deviation Pixel Distribution for each channel within the RGB Color Space')\n",
        "# Getting a tight layout\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(top=0.9)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blab9umLQlSL"
      },
      "source": [
        "Observing the figure above, it is possible to infer that there is a slightly difference between the roses and sunflowers STD images distributions. The latter has a blue channel STD images distribution with uniform-ish shape. Therefore, the STD of the pixel intensity can also be great feature candidate to compose the modeling dataset. \n",
        "\n",
        "For now, we already have enough features to compose our data preparation dataset. Let's dive into that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSuCjp_3_GcY"
      },
      "source": [
        "# 3. Data Preparation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpUB9uYcke9X"
      },
      "source": [
        "### - Extracting features from images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "485_5MEhj8M0"
      },
      "source": [
        "def extract_features(\n",
        "    image : np.array,\n",
        "    ) -> list:\n",
        "    \"\"\"\n",
        "    This function extracts some statistics from the image and transforms it into\n",
        "    features that will be used for modeling. This function returns a list of \n",
        "    float numbers.\n",
        "    \"\"\"\n",
        "\t  # Splitting up the image color space channels into separate variables\n",
        "    (R, G, B) = image[:, :, 0], image[:, :, 1], image[:, :, 2] \n",
        "    # Extraindo as features para cada canal\n",
        "    features = [\n",
        "    np.mean(R), \n",
        "    np.mean(G), \n",
        "    np.mean(B), \n",
        "    np.std(R), \n",
        "    np.std(G),\n",
        "    np.std(B),\n",
        "    ]\n",
        "    # Returning the feature list\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt7JN8yK3fT-"
      },
      "source": [
        "### - Data preparation pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7JL75E0j8Se"
      },
      "source": [
        "def data_preparation_pipeline(\n",
        "    data_dir : pathlib.PosixPath, \n",
        "    categories : list = ['roses','sunflowers'],\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Realiza a preparação dos dados retornando um `pd.DataFrame` com o conjunto\n",
        "    de dados composto pelas variáveis e alvos.\n",
        "    \"\"\"\n",
        "    # Creating lists to store the images and labels, respectivelly\n",
        "    data = []\n",
        "    # Storing image paths for each category that was parsed\n",
        "    for cat in categories:\n",
        "        img_paths_cat = list(data_dir.glob(f'{cat}/*'))\n",
        "        # Reading the image throught provided path\n",
        "        for path in img_paths_cat:\n",
        "            img_cat = load_image(path)\n",
        "            # Extract features\n",
        "            feature_cat = extract_features(img_cat)\n",
        "            # Storing variables\n",
        "            data.append(feature_cat+[img_cat]+[cat])\n",
        "    \n",
        "    # Converting array to pandas\n",
        "    columns = ['Rm','Gm','Bm','Rs','Gs','Bs','image','target']    \n",
        "    return pd.DataFrame(data, columns=columns)\n",
        "\n",
        "# Running the data preparation pipeline function\n",
        "data = data_preparation_pipeline(data_dir, categories=['roses', 'sunflowers'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpAXCKKgUEjd"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FezRRyjU7Hp"
      },
      "source": [
        "Here is the pandas dataframe containing all the features necessary for our modeling.\n",
        "\n",
        "### - Exploring category balance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZG-dRCo5LjE"
      },
      "source": [
        "# We have to check the classes balance\n",
        "data['target'].value_counts(normalize=True).plot.barh(alpha=0.5,ec='k')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfrN_n1A51K9"
      },
      "source": [
        "Then, we conclude that the dataset is pretty much balanced and there is no need to explore oversampling or undersampling techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zolIfro99Gim"
      },
      "source": [
        "### Bivariate Analysis\n",
        "\n",
        "We want to explore the relationship between two features, and to be able to check all the possible combinations. In order to keep it simple, we will run just scatterplots and histograms with the help of Seaborn.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ABUp4Db-SlR"
      },
      "source": [
        "sns.pairplot(data.drop(labels=['image'],axis=1), hue='target', \n",
        "             diag_kind='hist')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZAOYo19-sIb"
      },
      "source": [
        "We can observe that some interactions can help to separate some points, like the `red mean (Rm)` and `green mean (Gm)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAS_aQ809PB5"
      },
      "source": [
        "### - Exploring Correlation\n",
        "\n",
        "Lastly, we are going to run a correlation test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqq6CQMF6e1N"
      },
      "source": [
        "corr = data.drop(labels=['target','image'],axis=1).corr()\n",
        "\n",
        "# Plotting the heatmap\n",
        "ax = sns.heatmap(\n",
        "    corr, \n",
        "    vmin=-1, vmax=1, center=0,\n",
        "    cmap=sns.diverging_palette(20, 220, n=200),\n",
        "    square=True,\n",
        "    annot=True,\n",
        ")\n",
        "# Fixing the x labels\n",
        "ax.set_xticklabels(\n",
        "    ax.get_xticklabels(),\n",
        "    rotation=45,\n",
        "    horizontalalignment='right'\n",
        ")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMWiHNCs8jAH"
      },
      "source": [
        "The strongest correlation caught by our eyes is between `Gm` and `Rm` (about 0.67). Even though we consider it a correlation (above 0.6), it is not supposed to be a big trouble for this example. Therefore, we are going to keep all the features in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKd5JEFM_MPW"
      },
      "source": [
        "# 3. Modeling\n",
        "\n",
        "### - Splitting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIQw6yrBiESR"
      },
      "source": [
        "def split_dataset(\n",
        "    df: pd.DataFrame,\n",
        "    val_ratio : float = 0.3,\n",
        "    shuffle : bool = True,\n",
        "    target='target',\n",
        "    random_state=42\n",
        ") -> [np.array,np.array,np.array,np.array]:\n",
        "    \"\"\"\n",
        "    Split the data, creating two datasets: play and validation by wrapping the \n",
        "    sklearn method `train_test_split`\n",
        "    \"\"\"\n",
        "    # Calling the sklearn method `train_test_split`\n",
        "    X_play, X_val, y_play, y_val = train_test_split(\n",
        "        df, df[target],\n",
        "        stratify=df[target],\n",
        "        test_size=val_ratio,\n",
        "        shuffle=shuffle,\n",
        "        random_state=random_state\n",
        "        )\n",
        "    # Removing the target\n",
        "    X_play = X_play.drop(labels=[target,'image'],axis=1)\n",
        "    X_val = X_val.drop(labels=[target,'image'],axis=1)\n",
        "    y_play = y_play\n",
        "    y_val = y_val\n",
        "\n",
        "    return X_play, X_val, y_play, y_val\n",
        "\n",
        "# Running the function to separate our dataset\n",
        "X_play, X_val, y_play, y_val = split_dataset(data)\n",
        "\n",
        "print(f\"X's shapes: {X_play.shape}, {X_val.shape}\")\n",
        "print(f\"y's shapes: {y_play.shape}, {y_val.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0Ow8h7aJlBd"
      },
      "source": [
        "def modeling(\n",
        "    X_play : np.array,\n",
        "    X_val : np.array,\n",
        "    y_play : np.array,\n",
        "    y_val : np.array,\n",
        "    model = None,\n",
        "    n_folds : int = 10,\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Executa a modelagem, treinando o modelo e retornando métricas para se\n",
        "    acompanhar a performance\n",
        "    \"\"\"\n",
        "    # Checking if there is a model provided by the user\n",
        "    if model == None:\n",
        "        raise Exception(\"You need to provide a model\")\n",
        "        \n",
        "    # Defining the cross-validation strategy\n",
        "    cv = StratifiedKFold(n_folds)\n",
        "\n",
        "    # Determining the score of the modeling\n",
        "    list_metrics = cross_val_score(\n",
        "        model, \n",
        "        X_play, \n",
        "        y_play, \n",
        "        cv=cv,\n",
        "        scoring='accuracy'\n",
        "        )\n",
        "    avg_accuracy_cv = np.mean(list_metrics) # Mean\n",
        "    std_accuracy_cv = np.std(list_metrics)  # STD\n",
        "\n",
        "    # Fitting the model with the play dataset\n",
        "    model.fit(X_play, y_play)\n",
        "    # Getting the accuracy from the validation dataset\n",
        "    accuracy_test = accuracy_score(y_val, model.predict(X_val))\n",
        "    dict_metrics = {\n",
        "        'CV Accuracy (mean)' : np.round(avg_accuracy_cv,3),\n",
        "        'CV Accuracy (std)' : np.round(std_accuracy_cv,3),\n",
        "        'Validation Accuracy' : np.round(accuracy_test,3)\n",
        "    }\n",
        "    return dict_metrics\n",
        "\n",
        "# Defining the model\n",
        "model = KNeighborsClassifier()\n",
        "# Running the modeling \n",
        "results = modeling(X_play, X_val, y_play, y_val, model=model, n_folds=10)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6st6WcMHuV-B"
      },
      "source": [
        "Let's try some different models in order to check which one is best."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP3r5pjAZA90"
      },
      "source": [
        "%%time \n",
        "\n",
        "# Defining a dictionary to store all the models we are going to test\n",
        "models = {\n",
        "    'LogisticRegression' : LogisticRegression(class_weight='balanced'),\n",
        "    'KNeighborsClassifier' : KNeighborsClassifier(),\n",
        "    'GaussianNB' : GaussianNB(),\n",
        "    'DecisionTreeClassifier' : DecisionTreeClassifier(),\n",
        "}\n",
        "# Creating a dictionary to store the results\n",
        "results = dict()\n",
        "# Iterating for each model in the models dictionary\n",
        "for name,model in models.items():\n",
        "  # Running the modeling function to get the results\n",
        "  model_result = modeling(X_play, X_val, y_play, y_val, model, n_folds=10)\n",
        "  # Storing the results into the results dictionary\n",
        "  results[name] = model_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlV0nVmhiL2h"
      },
      "source": [
        "# Displaying the results\n",
        "pd.DataFrame(results).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdhiu-1OxqGM"
      },
      "source": [
        "# Fitting the best model with our play data\n",
        "model = models['LogisticRegression'].fit(X_play,y_play)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn8yyhxmx9wH"
      },
      "source": [
        "# Getting the index of an image from the validation dataset\n",
        "testing_index = 15\n",
        "\n",
        "# Predicting the output\n",
        "prediction = model.predict([X_val.iloc[testing_index]])\n",
        "print(f\"The prediction was: '{prediction}'\")\n",
        "\n",
        "# Locating the true results from the dataset\n",
        "idx = X_val.iloc[testing_index].name\n",
        "category = y_val.iloc[testing_index]\n",
        "print(f\"True category is: '{category}'\")\n",
        "print(f\"Index is: '{idx}'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK9FMn9Hx94b"
      },
      "source": [
        "# Selecting the image\n",
        "image_tmp = data.loc[idx,'image']\n",
        "\n",
        "# Displaying the image\n",
        "fig,ax = plt.subplots(1,1,figsize=(7,7))\n",
        "ax.imshow(image_tmp)\n",
        "ax.set_xlabel('width, [px]')\n",
        "ax.set_ylabel('height, [px]')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTXG552d6t7q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}